{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2dc8ea6",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook walks through the steps to load pre-trained hyper-representation models, instanciate a model, load the checkpoint, load the dataset and do a forward pass.   \n",
    "Make sure to install the ghrp package by running `pip3 install .` in the main directory and download the data first by running `bash download_data.sh` in `/data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ceb814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.logger import DEFAULT_LOGGERS\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from ghrp.model_definitions.def_simclr_ae_module import SimCLRAEModule\n",
    "from ghrp.checkpoints_to_datasets.dataset_simclr import SimCLRDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set which hyper-representation to load\n",
    "\n",
    "PATH_ROOT = Path(\"./../data/hyper_representations/mnist\")\n",
    "# PATH_ROOT = Path(\"./../data/hyper_representations/svhn\")\n",
    "# PATH_ROOT = Path(\"./../data/hyper_representations/cifar10\")\n",
    "# PATH_ROOT = Path(\"./../data/hyper_representations/stl10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config_path = PATH_ROOT.joinpath('config_ae.json')\n",
    "config = json.load(config_path.open('r'))\n",
    "config['dataset::dump'] = PATH_ROOT.joinpath('dataset.pt').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set resources\n",
    "gpus = 1 if torch.cuda.is_available() else 0\n",
    "cpus = 4\n",
    "resources_per_trial = {\"cpu\": cpus, \"gpu\": gpus}\n",
    "\n",
    "device = torch.device('cuda') if gpus>0 else torch.device('cpu')\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate model\n",
    "module = SimCLRAEModule(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint\n",
    "checkpoint_path = PATH_ROOT.joinpath('checkpoint_ae.pt')\n",
    "checkpoint = torch.load(checkpoint_path,map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint to model\n",
    "module.model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset_path = PATH_ROOT.joinpath('dataset.pt')\n",
    "dataset = torch.load(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1dcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test weights\n",
    "weights_test = dataset['testset'].__get_weights__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propagate test weights\n",
    "with torch.no_grad():\n",
    "    z, y = module.forward(weights_test.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a64848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z are the latent representations, y the reconstructed weights\n",
    "print(z.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b7697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
